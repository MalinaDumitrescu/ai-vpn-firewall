{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f85032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\data\\processed\\vnat\\xgb_features.parquet\n",
      "Rows: 33711 Cols: 69\n",
      "Feature columns saved: ..\\artifacts\\features\\feature_columns.json\n",
      "Example feature cols: ['pkt_count_total', 'byte_count_total', 'flow_duration', 'pkt_rate', 'byte_rate', 'pkt_count_up', 'pkt_count_down', 'byte_count_up', 'byte_count_down', 'pkt_ratio_up_down']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_id</th>\n",
       "      <th>pkt_count_total</th>\n",
       "      <th>byte_count_total</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>pkt_rate</th>\n",
       "      <th>byte_rate</th>\n",
       "      <th>pkt_count_up</th>\n",
       "      <th>pkt_count_down</th>\n",
       "      <th>byte_count_up</th>\n",
       "      <th>byte_count_down</th>\n",
       "      <th>...</th>\n",
       "      <th>iat_down_q25</th>\n",
       "      <th>iat_down_q75</th>\n",
       "      <th>size_bin_frac_1</th>\n",
       "      <th>size_bin_frac_2</th>\n",
       "      <th>size_bin_frac_3</th>\n",
       "      <th>size_bin_frac_4</th>\n",
       "      <th>size_bin_frac_5</th>\n",
       "      <th>size_bin_frac_6</th>\n",
       "      <th>capture_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>11.120431</td>\n",
       "      <td>2.467970</td>\n",
       "      <td>2.328308</td>\n",
       "      <td>8.741171</td>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "      <td>8.934982</td>\n",
       "      <td>11.001183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>vpn_youtube_capture2.pcap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.962845</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>8.561072</td>\n",
       "      <td>12.823563</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>4.382027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nonvpn_sftp_newcapture1.pcap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.844187</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>8.642086</td>\n",
       "      <td>12.785047</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nonvpn_sftp_newcapture1.pcap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>10.842850</td>\n",
       "      <td>0.284168</td>\n",
       "      <td>5.721195</td>\n",
       "      <td>11.955581</td>\n",
       "      <td>57</td>\n",
       "      <td>43</td>\n",
       "      <td>10.712950</td>\n",
       "      <td>8.737773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>nonvpn_sftp_newcapture1.pcap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5.036953</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>8.483251</td>\n",
       "      <td>12.820337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>4.634729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nonvpn_sftp_newcapture1.pcap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   flow_id  pkt_count_total  byte_count_total  flow_duration  pkt_rate  \\\n",
       "0        0              100         11.120431       2.467970  2.328308   \n",
       "1        1                2          4.962845       0.000383  8.561072   \n",
       "2        2                2          4.844187       0.000353  8.642086   \n",
       "3        3              100         10.842850       0.284168  5.721195   \n",
       "4        4                2          5.036953       0.000414  8.483251   \n",
       "\n",
       "   byte_rate  pkt_count_up  pkt_count_down  byte_count_up  byte_count_down  \\\n",
       "0   8.741171            39              61       8.934982        11.001183   \n",
       "1  12.823563             1               1       4.158883         4.382027   \n",
       "2  12.785047             1               1       4.158883         4.158883   \n",
       "3  11.955581            57              43      10.712950         8.737773   \n",
       "4  12.820337             1               1       3.951244         4.634729   \n",
       "\n",
       "   ...  iat_down_q25  iat_down_q75  size_bin_frac_1  size_bin_frac_2  \\\n",
       "0  ...      0.000041      0.000519             0.03             0.52   \n",
       "1  ...      0.000000      0.000000             1.00             0.00   \n",
       "2  ...      0.000000      0.000000             1.00             0.00   \n",
       "3  ...      0.000163      0.002826             0.33             0.30   \n",
       "4  ...      0.000000      0.000000             0.50             0.50   \n",
       "\n",
       "   size_bin_frac_3  size_bin_frac_4  size_bin_frac_5  size_bin_frac_6  \\\n",
       "0             0.01             0.05             0.01             0.38   \n",
       "1             0.00             0.00             0.00             0.00   \n",
       "2             0.00             0.00             0.00             0.00   \n",
       "3             0.05             0.01             0.01             0.30   \n",
       "4             0.00             0.00             0.00             0.00   \n",
       "\n",
       "                     capture_id  label  \n",
       "0     vpn_youtube_capture2.pcap      1  \n",
       "1  nonvpn_sftp_newcapture1.pcap      0  \n",
       "2  nonvpn_sftp_newcapture1.pcap      0  \n",
       "3  nonvpn_sftp_newcapture1.pcap      0  \n",
       "4  nonvpn_sftp_newcapture1.pcap      0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "VNAT_H5 = Path(\"../data/raw/vnat/VNAT_Dataframe_release_1.h5\")\n",
    "FLOWS   = Path(\"../data/processed/vnat/flows.parquet\")\n",
    "\n",
    "OUT_DIR = Path(\"../data/processed/vnat\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_XGB  = OUT_DIR / \"xgb_features.parquet\"\n",
    "OUT_COLS = Path(\"../artifacts/features/feature_columns.json\")\n",
    "OUT_COLS.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N = 100\n",
    "EPS = 1e-9\n",
    "\n",
    "# Load VNAT and align indices to flow_id\n",
    "df = pd.read_hdf(VNAT_H5).reset_index(drop=True)  # critical\n",
    "flows = pd.read_parquet(FLOWS).set_index(\"flow_id\").sort_index()\n",
    "\n",
    "assert len(df) == len(flows), f\"Mismatch df({len(df)}) vs flows({len(flows)})\"\n",
    "\n",
    "# ---- helpers ----\n",
    "def safe_stats(x: np.ndarray, prefix: str):\n",
    "    if x.size == 0:\n",
    "        return {\n",
    "            f\"{prefix}_mean\": 0.0, f\"{prefix}_std\": 0.0, f\"{prefix}_min\": 0.0, f\"{prefix}_max\": 0.0,\n",
    "            f\"{prefix}_median\": 0.0, f\"{prefix}_q25\": 0.0, f\"{prefix}_q75\": 0.0\n",
    "        }\n",
    "    return {\n",
    "        f\"{prefix}_mean\": float(np.mean(x)),\n",
    "        f\"{prefix}_std\": float(np.std(x)),\n",
    "        f\"{prefix}_min\": float(np.min(x)),\n",
    "        f\"{prefix}_max\": float(np.max(x)),\n",
    "        f\"{prefix}_median\": float(np.median(x)),\n",
    "        f\"{prefix}_q25\": float(np.quantile(x, 0.25)),\n",
    "        f\"{prefix}_q75\": float(np.quantile(x, 0.75)),\n",
    "    }\n",
    "\n",
    "def size_hist_fracs(abs_sizes: np.ndarray, pkt_count: int):\n",
    "    bins = [(0,99),(100,299),(300,599),(600,899),(900,1199),(1200, None)]\n",
    "    out = {}\n",
    "    denom = max(pkt_count, 1)\n",
    "    for i, (lo, hi) in enumerate(bins, start=1):\n",
    "        if hi is None:\n",
    "            c = int(np.sum(abs_sizes >= lo))\n",
    "        else:\n",
    "            c = int(np.sum((abs_sizes >= lo) & (abs_sizes <= hi)))\n",
    "        out[f\"size_bin_frac_{i}\"] = c / denom\n",
    "    return out\n",
    "\n",
    "def iat_from_times(t: np.ndarray):\n",
    "    if t.size < 2:\n",
    "        return np.array([], dtype=np.float64)\n",
    "    d = np.diff(t)\n",
    "    d[d < 0] = 0.0\n",
    "    return d\n",
    "\n",
    "# ---- build features ----\n",
    "rows = []\n",
    "for flow_id in flows.index.to_numpy():\n",
    "    ts = np.asarray(df.at[flow_id, \"timestamps\"], dtype=np.float64)\n",
    "    sz = np.asarray(df.at[flow_id, \"sizes\"], dtype=np.float64)\n",
    "    dr = np.asarray(df.at[flow_id, \"directions\"], dtype=np.int64)\n",
    "\n",
    "    if ts.size == 0:\n",
    "        rows.append({\n",
    "            \"flow_id\": int(flow_id),\n",
    "            \"pkt_count_total\": 0,\n",
    "            \"byte_count_total\": 0.0,\n",
    "            \"flow_duration\": 0.0,\n",
    "            \"pkt_rate\": 0.0,\n",
    "            \"byte_rate\": 0.0,\n",
    "            \"pkt_count_up\": 0,\n",
    "            \"pkt_count_down\": 0,\n",
    "            \"byte_count_up\": 0.0,\n",
    "            \"byte_count_down\": 0.0,\n",
    "            \"pkt_ratio_up_down\": 1.0,\n",
    "            \"byte_ratio_up_down\": 1.0,\n",
    "            \"up_fraction_bytes\": 0.0,\n",
    "            \"down_fraction_bytes\": 0.0,\n",
    "            \"cv_pkt_size\": 0.0,\n",
    "            \"cv_iat\": 0.0,\n",
    "            \"max_iat_over_median_iat\": 0.0,\n",
    "            \"pkt_count_observed\": 0,\n",
    "            \"window_complete\": 0,\n",
    "            **safe_stats(np.array([], dtype=np.float64), \"pkt_size_all\"),\n",
    "            **safe_stats(np.array([], dtype=np.float64), \"pkt_size_up\"),\n",
    "            **safe_stats(np.array([], dtype=np.float64), \"pkt_size_down\"),\n",
    "            **safe_stats(np.array([], dtype=np.float64), \"iat_all\"),\n",
    "            **safe_stats(np.array([], dtype=np.float64), \"iat_up\"),\n",
    "            **safe_stats(np.array([], dtype=np.float64), \"iat_down\"),\n",
    "            **{f\"size_bin_frac_{i}\": 0.0 for i in range(1, 7)}\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # sort by time (matches CNN)\n",
    "    order = np.argsort(ts)\n",
    "    ts, sz, dr = ts[order], sz[order], dr[order]\n",
    "\n",
    "    k = int(min(sz.size, N))\n",
    "    ts = ts[:k]\n",
    "    sz = sz[:k]\n",
    "    dr = dr[:k]\n",
    "\n",
    "    up_mask = (dr == 1)\n",
    "    down_mask = (dr == 0)\n",
    "\n",
    "    sz_up = sz[up_mask]\n",
    "    sz_down = sz[down_mask]\n",
    "\n",
    "    iat_all = iat_from_times(ts)\n",
    "    iat_up = iat_from_times(ts[up_mask])\n",
    "    iat_down = iat_from_times(ts[down_mask])\n",
    "\n",
    "    duration = float(ts[-1] - ts[0]) if ts.size >= 2 else 0.0\n",
    "    pkt_count_total = int(k)\n",
    "    byte_count_total = float(np.sum(sz))\n",
    "\n",
    "    pkt_rate = pkt_count_total / (duration + EPS)\n",
    "    byte_rate = byte_count_total / (duration + EPS)\n",
    "\n",
    "    pkt_count_up = int(sz_up.size)\n",
    "    pkt_count_down = int(sz_down.size)\n",
    "    byte_count_up = float(np.sum(sz_up)) if sz_up.size else 0.0\n",
    "    byte_count_down = float(np.sum(sz_down)) if sz_down.size else 0.0\n",
    "\n",
    "    pkt_ratio_up_down = (pkt_count_up + 1) / (pkt_count_down + 1)\n",
    "    byte_ratio_up_down = (byte_count_up + 1.0) / (byte_count_down + 1.0)\n",
    "    up_fraction_bytes = byte_count_up / (byte_count_total + EPS)\n",
    "    down_fraction_bytes = byte_count_down / (byte_count_total + EPS)\n",
    "\n",
    "    size_all_stats = safe_stats(sz, \"pkt_size_all\")\n",
    "    size_up_stats = safe_stats(sz_up, \"pkt_size_up\")\n",
    "    size_down_stats = safe_stats(sz_down, \"pkt_size_down\")\n",
    "\n",
    "    iat_all_stats = safe_stats(iat_all, \"iat_all\")\n",
    "    iat_up_stats = safe_stats(iat_up, \"iat_up\")\n",
    "    iat_down_stats = safe_stats(iat_down, \"iat_down\")\n",
    "\n",
    "    cv_pkt_size = size_all_stats[\"pkt_size_all_std\"] / (size_all_stats[\"pkt_size_all_mean\"] + EPS)\n",
    "    cv_iat = iat_all_stats[\"iat_all_std\"] / (iat_all_stats[\"iat_all_mean\"] + EPS)\n",
    "    max_iat_over_median_iat = (iat_all_stats[\"iat_all_max\"] + EPS) / (iat_all_stats[\"iat_all_median\"] + EPS)\n",
    "\n",
    "    hist = size_hist_fracs(np.abs(sz), pkt_count_total)\n",
    "\n",
    "    pkt_count_observed = pkt_count_total\n",
    "    window_complete = 1 if pkt_count_total == N else 0\n",
    "\n",
    "    row = {\n",
    "        \"flow_id\": int(flow_id),\n",
    "\n",
    "        \"pkt_count_total\": pkt_count_total,\n",
    "        \"byte_count_total\": byte_count_total,\n",
    "        \"flow_duration\": duration,\n",
    "        \"pkt_rate\": pkt_rate,\n",
    "        \"byte_rate\": byte_rate,\n",
    "\n",
    "        \"pkt_count_up\": pkt_count_up,\n",
    "        \"pkt_count_down\": pkt_count_down,\n",
    "        \"byte_count_up\": byte_count_up,\n",
    "        \"byte_count_down\": byte_count_down,\n",
    "        \"pkt_ratio_up_down\": pkt_ratio_up_down,\n",
    "        \"byte_ratio_up_down\": byte_ratio_up_down,\n",
    "        \"up_fraction_bytes\": up_fraction_bytes,\n",
    "        \"down_fraction_bytes\": down_fraction_bytes,\n",
    "\n",
    "        \"cv_pkt_size\": float(cv_pkt_size),\n",
    "        \"cv_iat\": float(cv_iat),\n",
    "        \"max_iat_over_median_iat\": float(max_iat_over_median_iat),\n",
    "\n",
    "        \"pkt_count_observed\": pkt_count_observed,\n",
    "        \"window_complete\": window_complete,\n",
    "    }\n",
    "\n",
    "    row.update(size_all_stats)\n",
    "    row.update(size_up_stats)\n",
    "    row.update(size_down_stats)\n",
    "\n",
    "    row.update(iat_all_stats)\n",
    "    row.update(iat_up_stats)\n",
    "    row.update(iat_down_stats)\n",
    "\n",
    "    row.update(hist)\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "xgb_df = pd.DataFrame(rows).sort_values(\"flow_id\").reset_index(drop=True)\n",
    "\n",
    "# attach capture_id + label so the features file is self-contained\n",
    "meta = flows.reset_index()[[\"flow_id\", \"capture_id\", \"label\"]]\n",
    "xgb_df = xgb_df.merge(meta, on=\"flow_id\", how=\"left\")\n",
    "\n",
    "assert not xgb_df[\"label\"].isna().any(), \"label missing after merge\"\n",
    "assert not xgb_df[\"capture_id\"].isna().any(), \"capture_id missing after merge\"\n",
    "\n",
    "# optional: log transforms for heavy tails (helps generalization)\n",
    "for col in [\"byte_count_total\", \"byte_count_up\", \"byte_count_down\", \"pkt_rate\", \"byte_rate\", \"flow_duration\"]:\n",
    "    xgb_df[col] = np.log1p(xgb_df[col].astype(float))\n",
    "\n",
    "# Save\n",
    "xgb_df.to_parquet(OUT_XGB, index=False, engine=\"pyarrow\")\n",
    "\n",
    "# Save ONLY feature columns (exclude meta)\n",
    "feature_cols = [c for c in xgb_df.columns if c not in [\"flow_id\", \"capture_id\", \"label\"]]\n",
    "OUT_COLS.write_text(json.dumps(feature_cols, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", OUT_XGB)\n",
    "print(\"Rows:\", len(xgb_df), \"Cols:\", len(xgb_df.columns))\n",
    "print(\"Feature columns saved:\", OUT_COLS)\n",
    "print(\"Example feature cols:\", feature_cols[:10])\n",
    "xgb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7c804b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33711, 69)\n",
      "Any NaNs: False\n",
      "Example columns: ['flow_id', 'pkt_count_total', 'byte_count_total', 'flow_duration', 'pkt_rate', 'byte_rate', 'pkt_count_up', 'pkt_count_down', 'byte_count_up', 'byte_count_down', 'pkt_ratio_up_down', 'byte_ratio_up_down']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "xgb = pd.read_parquet(\"../data/processed/vnat/xgb_features.parquet\")\n",
    "print(xgb.shape)\n",
    "print(\"Any NaNs:\", xgb.isna().any().any())\n",
    "print(\"Example columns:\", list(xgb.columns)[:12])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
