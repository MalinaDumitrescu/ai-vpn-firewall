{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc6f404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows Train: 20240 Val: 562 Test: 12909\n",
      "Train class_counts: {0: 20011, 1: 229}\n",
      "Val class_counts: {0: 425, 1: 137}\n",
      "Test class_counts: {0: 12896, 1: 13}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "XGB_FEATS = Path(\"../data/processed/vnat/xgb_features.parquet\")\n",
    "FLOWS     = Path(\"../data/processed/vnat/flows.parquet\")\n",
    "\n",
    "train_caps = set(Path(\"../data/splits/vnat_train_captures.txt\").read_text(encoding=\"utf-8\").splitlines())\n",
    "val_caps   = set(Path(\"../data/splits/vnat_val_captures.txt\").read_text(encoding=\"utf-8\").splitlines())\n",
    "test_caps  = set(Path(\"../data/splits/vnat_test_captures.txt\").read_text(encoding=\"utf-8\").splitlines())\n",
    "\n",
    "xgb_df = pd.read_parquet(XGB_FEATS)\n",
    "flows  = pd.read_parquet(FLOWS).set_index(\"flow_id\")\n",
    "\n",
    "# Align by flow_id\n",
    "xgb_df = xgb_df.set_index(\"flow_id\").sort_index()\n",
    "flows = flows.sort_index()\n",
    "\n",
    "assert xgb_df.index.equals(flows.index), \"flow_id mismatch between xgb_features and flows\"\n",
    "\n",
    "# Build indices by capture split\n",
    "train_ids = flows.index[flows[\"capture_id\"].isin(train_caps)]\n",
    "val_ids   = flows.index[flows[\"capture_id\"].isin(val_caps)]\n",
    "test_ids  = flows.index[flows[\"capture_id\"].isin(test_caps)]\n",
    "\n",
    "print(\"Flows Train:\", len(train_ids), \"Val:\", len(val_ids), \"Test:\", len(test_ids))\n",
    "print(\"Train class_counts:\", flows.loc[train_ids, \"label\"].value_counts().to_dict())\n",
    "print(\"Val class_counts:\", flows.loc[val_ids, \"label\"].value_counts().to_dict())\n",
    "print(\"Test class_counts:\", flows.loc[test_ids, \"label\"].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15998fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (20240, 66) X_val: (562, 66) X_test: (12909, 66)\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [c for c in xgb_df.columns if c not in [\"capture_id\", \"label\"]]\n",
    "# safety: drop anything non-numeric (shouldn't exist, but keep safe)\n",
    "xgb_df = xgb_df[feature_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "assert not xgb_df.isna().any().any(), \"NaNs appeared after numeric coercion\"\n",
    "\n",
    "X_train = xgb_df.loc[train_ids].to_numpy(dtype=np.float32)\n",
    "X_val   = xgb_df.loc[val_ids].to_numpy(dtype=np.float32)\n",
    "X_test  = xgb_df.loc[test_ids].to_numpy(dtype=np.float32)\n",
    "\n",
    "y_train = flows.loc[train_ids, \"label\"].to_numpy(dtype=np.int32)\n",
    "y_val   = flows.loc[val_ids, \"label\"].to_numpy(dtype=np.int32)\n",
    "y_test  = flows.loc[test_ids, \"label\"].to_numpy(dtype=np.int32)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape, \"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2207e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train positives: 229 Train negatives: 20011\n",
      "scale_pos_weight: 87.38427947598254\n"
     ]
    }
   ],
   "source": [
    "n_pos = int((y_train == 1).sum())\n",
    "n_neg = int((y_train == 0).sum())\n",
    "scale_pos_weight = n_neg / max(n_pos, 1)\n",
    "\n",
    "print(\"Train positives:\", n_pos, \"Train negatives:\", n_neg)\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717e0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.60352\n",
      "[50]\tvalidation_0-logloss:0.04263\n",
      "[100]\tvalidation_0-logloss:0.01557\n",
      "[150]\tvalidation_0-logloss:0.01489\n",
      "[200]\tvalidation_0-logloss:0.01598\n",
      "[250]\tvalidation_0-logloss:0.01613\n",
      "[300]\tvalidation_0-logloss:0.01595\n",
      "[350]\tvalidation_0-logloss:0.01598\n",
      "[400]\tvalidation_0-logloss:0.01617\n",
      "[450]\tvalidation_0-logloss:0.01602\n",
      "[500]\tvalidation_0-logloss:0.01601\n",
      "[550]\tvalidation_0-logloss:0.01593\n",
      "[600]\tvalidation_0-logloss:0.01600\n",
      "[650]\tvalidation_0-logloss:0.01588\n",
      "[700]\tvalidation_0-logloss:0.01586\n",
      "[750]\tvalidation_0-logloss:0.01607\n",
      "[800]\tvalidation_0-logloss:0.01583\n",
      "[850]\tvalidation_0-logloss:0.01587\n",
      "[900]\tvalidation_0-logloss:0.01611\n",
      "[950]\tvalidation_0-logloss:0.01590\n",
      "[1000]\tvalidation_0-logloss:0.01584\n",
      "[1050]\tvalidation_0-logloss:0.01581\n",
      "[1100]\tvalidation_0-logloss:0.01593\n",
      "[1150]\tvalidation_0-logloss:0.01599\n",
      "[1200]\tvalidation_0-logloss:0.01604\n",
      "[1250]\tvalidation_0-logloss:0.01606\n",
      "[1300]\tvalidation_0-logloss:0.01608\n",
      "[1350]\tvalidation_0-logloss:0.01601\n",
      "[1400]\tvalidation_0-logloss:0.01589\n",
      "[1450]\tvalidation_0-logloss:0.01591\n",
      "[1500]\tvalidation_0-logloss:0.01590\n",
      "[1550]\tvalidation_0-logloss:0.01605\n",
      "[1600]\tvalidation_0-logloss:0.01611\n",
      "[1650]\tvalidation_0-logloss:0.01622\n",
      "[1700]\tvalidation_0-logloss:0.01610\n",
      "[1750]\tvalidation_0-logloss:0.01602\n",
      "[1800]\tvalidation_0-logloss:0.01585\n",
      "[1850]\tvalidation_0-logloss:0.01590\n",
      "[1900]\tvalidation_0-logloss:0.01586\n",
      "[1950]\tvalidation_0-logloss:0.01593\n",
      "[1999]\tvalidation_0-logloss:0.01588\n",
      "Best iteration: None\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 2000,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(**params)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=50,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "print(\"Best iteration:\", model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d12630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL @0.5: {'thr': 0.5, 'tn': np.int64(424), 'fp': np.int64(1), 'fn': np.int64(1), 'tp': np.int64(136), 'recall': np.float64(0.9927007299270001), 'fpr': np.float64(0.0023529411764705824)}\n",
      "TEST @0.5: {'thr': 0.5, 'tn': np.int64(12893), 'fp': np.int64(3), 'fn': np.int64(3), 'tp': np.int64(10), 'recall': np.float64(0.7692307692307101), 'fpr': np.float64(0.00023263027295285357)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "\n",
    "def eval_at_threshold(y_true, probs, thr=0.5):\n",
    "    y_pred = (probs >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    recall = tp / (tp + fn + 1e-12)\n",
    "    fpr = fp / (fp + tn + 1e-12)\n",
    "    return {\"thr\": thr, \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp, \"recall\": recall, \"fpr\": fpr}\n",
    "\n",
    "val_probs = model.predict_proba(X_val)[:, 1]\n",
    "test_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"VAL @0.5:\", eval_at_threshold(y_val, val_probs, 0.5))\n",
    "print(\"TEST @0.5:\", eval_at_threshold(y_test, test_probs, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a730f096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: ..\\artifacts\\xgb\\xgb_model.json\n",
      "Saved metrics: ..\\artifacts\\xgb\\metrics.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "ART_DIR = Path(\"../artifacts/xgb\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save model\n",
    "model_path = ART_DIR / \"xgb_model.json\"\n",
    "model.save_model(str(model_path))\n",
    "\n",
    "# save feature columns\n",
    "Path(\"../artifacts/features\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../artifacts/features/feature_columns.json\").write_text(\n",
    "    json.dumps(feature_cols, indent=2), encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "def to_py(obj):\n",
    "    \"\"\"Convert numpy scalars/arrays recursively to Python types for JSON.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: to_py(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [to_py(v) for v in obj]\n",
    "    if isinstance(obj, (np.integer,)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, (np.floating,)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "metrics = {\n",
    "    \"train_pos\": int(n_pos),\n",
    "    \"train_neg\": int(n_neg),\n",
    "    \"scale_pos_weight\": float(scale_pos_weight),\n",
    "    \"val_at_0_5\": eval_at_threshold(y_val, val_probs, 0.5),\n",
    "    \"test_at_0_5\": eval_at_threshold(y_test, test_probs, 0.5),\n",
    "}\n",
    "\n",
    "(Path(\"../artifacts/xgb/metrics.json\")).write_text(\n",
    "    json.dumps(to_py(metrics), indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"Saved model:\", model_path)\n",
    "print(\"Saved metrics:\", ART_DIR / \"metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734ae575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved XGB probs to: ..\\artifacts\\xgb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "OUT = Path(\"../artifacts/xgb\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(OUT / \"val_probs.npy\", val_probs)\n",
    "np.save(OUT / \"val_y.npy\", y_val)\n",
    "\n",
    "np.save(OUT / \"test_probs.npy\", test_probs)\n",
    "np.save(OUT / \"test_y.npy\", y_test)\n",
    "\n",
    "print(\"Saved XGB probs to:\", OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
